Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Curiosity Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Curiosity Reward,Is Training
5000,0.5206361,35.91129032258065,-105.38308,99.07329,-2.613991850457056,-2.613991850457056,0.0,1.0
10000,0.5767378,84.48148148148148,-75.141235,91.23894,-1.9342163617638024,-1.9342163617638024,0.0,1.0
15000,0.4885428,41.76984126984127,-90.30145,103.935265,-2.39419760948254,-2.39419760948254,34.5,1.0
20000,0.55376875,40.19230769230769,-103.47984,78.83659,-2.371722881205892,-2.371722881205892,41.06106870229008,1.0
25000,0.542484,35.976,-84.623795,92.947754,-2.475609584748745,-2.475609584748745,35.64518047714233,1.0
30000,0.5004075,37.125984251968504,-77.29496,97.1222,-2.5257626740882793,-2.5257626740882793,37.339461167653404,1.0
35000,0.501053,40.6640625,-74.478874,98.46474,-2.369908502917419,-2.369908502917419,31.14683814518616,1.0
40000,0.44685635,34.00763358778626,-76.41693,104.576965,-2.4235694515909856,-2.4235694515909856,18.62412205412415,1.0
45000,0.5454715,40.712,-77.21492,98.14669,-2.50283597689867,-2.50283597689867,18.755032506942747,1.0
50000,0.4642799,35.01418439716312,-65.018005,101.741264,-2.305024095355196,-2.305024095355196,7.529918932068617,1.0
55000,0.4885138,37.713178294573645,-72.81382,77.739006,-2.3836812342633493,-2.3836812342633493,9.539626618556213,1.0
60000,0.5445627,35.94736842105263,-54.305573,91.7771,-2.4746781888985097,-2.4746781888985097,3.8301904596514382,1.0
65000,0.50723004,38.343511450381676,-68.181305,93.73585,-2.469005281726519,-2.469005281726519,6.262918791941819,1.0
70000,0.5022151,40.4375,-50.646866,99.78645,-2.439358252826638,-2.439358252826638,5.663896597753183,1.0
75000,0.44677886,33.523809523809526,-71.0329,98.581566,-2.4738404714753703,-2.4738404714753703,1.8688083432008704,1.0
80000,0.49342778,40.75590551181102,-56.12733,93.67784,-2.4277163739316165,-2.4277163739316165,3.5598284412808425,1.0
